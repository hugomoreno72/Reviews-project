{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a6c1a3-264c-4faa-94cd-03f0becc5ccb",
   "metadata": {},
   "source": [
    "This dataset was taken from Kaggle: IMDB Dataset of 50K Movie Reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece480f6-5e62-4c7a-b7e0-8a76a1132409",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f190e84-0158-4efb-a825-aa0025eb2b55",
   "metadata": {},
   "source": [
    "The goal is to find which ML model is best suited to predict sentiment given a review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6df53c-794e-43b5-9133-40fdfa4d06dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_review = pd.read_csv('IMDB Dataset.csv')\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ce7b2-0b08-40e5-886c-b90d271ea2f9",
   "metadata": {},
   "source": [
    "Im gonna take a smaller sample of 10k rows to make processing faster and get imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b311ca1a-18ee-46fc-84c7-ac973a31742e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive     9000\n",
       "negative     1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9000 positives\n",
    "df_positive = df_review[df_review['sentiment']=='positive'][:9000]\n",
    "# 1000 negatives\n",
    "df_negative = df_review[df_review['sentiment']=='negative'][:1000]\n",
    "\n",
    "df_review_imb = pd.concat([df_positive, df_negative])\n",
    "df_review_imb.value_counts(['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652b370f-398f-4b79-af6a-bc33b94e2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import  RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "df_review_bal, df_review_bal['sentiment']=rus.fit_resample(df_review_imb[['review']],\n",
    "                                                           df_review_imb['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de79f5f-729c-4120-8925-33ae0840fc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    9000\n",
      "negative    1000\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "sentiment\n",
      "negative    1000\n",
      "positive    1000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_review_imb.value_counts('sentiment'),\"\\n\")\n",
    "print(df_review_bal.value_counts('sentiment'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90c9fdd-2e41-4aaf-99ec-a7d6790b426e",
   "metadata": {},
   "source": [
    "\n",
    "Firstly had 50k rows, then moved to 10k (9k positives and 1k negatives) and finally we undersampled it getting 2k samples (1k positives and 1k negatives).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd96368-1c40-4bca-a22a-2ed1874d12e5",
   "metadata": {},
   "source": [
    "## Data Split (Train/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7a5916-c923-43fb-9799-b9004e557cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_review_bal, test_size=0.33, random_state=0)\n",
    "train_x, train_y = train['review'], train['sentiment']\n",
    "test_x, test_y = test['review'], test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5e0f7-fb57-4738-ad55-1dee527ee80d",
   "metadata": {},
   "source": [
    "These algorithms expect numerical data rather than text, so we have to convert text into numerical info. One way to do it is using TFIDF (Term Frequency – Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5101446e-93d5-4962-a025-0c21d7f7c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "train_x_vector = tfidf.fit_transform(train_x)\n",
    "# also fit the test_x_vector\n",
    "test_x_vector = tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6dcc5c-e3c5-4689-9af8-a88925eb04cd",
   "metadata": {},
   "source": [
    "### ML algorith -> Supervised learning -> Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e51ce-89f1-4516-a8a9-d84323d418bf",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e08f4d6-16b2-4fd7-8b7d-7a3476ba4117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel=\"linear\")\n",
    "print(svc.fit(train_x_vector, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "486fe151-1743-430c-bd74-0e6f8edd8119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n",
      "['positive']\n",
      "['negative']\n"
     ]
    }
   ],
   "source": [
    "### Testing\n",
    "\n",
    "print(svc.predict(tfidf.transform(['A good movie'])))\n",
    "print(svc.predict(tfidf.transform(['An excellent movie'])))\n",
    "print(svc.predict(tfidf.transform(['I did not like this movie at all'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc31f6-d251-4ea6-8935-238ebfe60581",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73a0962c-6311-4bc2-ac92-bdc468201778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "print(dec_tree.fit(train_x_vector, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ee2289a-6f57-4d80-a14e-70493282fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "print(gnb.fit(train_x_vector.toarray(), train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0516c732-2547-4240-82c7-d0dfdbd8463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "print(log_reg.fit(train_x_vector, train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47331dae-ac83-4e82-bcda-f11b1ac7f13d",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84e948-1ce3-43e6-9c83-69b08d47feec",
   "metadata": {},
   "source": [
    "#### Mean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d61829b5-4710-495a-8d99-899872f2fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model precission:  0.826\n",
      "Decision tree model precission:  0.670\n",
      "Gaussian naive bayes model precission:  0.633\n",
      "Logistic regression model precission:  0.812\n"
     ]
    }
   ],
   "source": [
    "print(f\"SVM model precission: {svc.score(test_x_vector, test_y): .3f}\")\n",
    "print(f\"Decision tree model precission: {dec_tree.score(test_x_vector, test_y): .3f}\")\n",
    "print(f\"Gaussian naive bayes model precission: {gnb.score(test_x_vector.toarray(), test_y): .3f}\")\n",
    "print(f\"Logistic regression model precission: {log_reg.score(test_x_vector, test_y): .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a143a-498f-45f0-b2a3-ab0231696835",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0223bc42-1758-4f45-9058-8353acf8b364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82861401, 0.82280431])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test_y, svc.predict(test_x_vector),\n",
    "         labels=['positive', 'negative'],\n",
    "         average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e03d2-01e1-4464-ada4-527435db22fc",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95400f04-2e46-4d9d-accd-466a24c6d379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.79      0.87      0.83       321\n",
      "    negative       0.86      0.79      0.82       339\n",
      "\n",
      "    accuracy                           0.83       660\n",
      "   macro avg       0.83      0.83      0.83       660\n",
      "weighted avg       0.83      0.83      0.83       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_y, \n",
    "                            svc.predict(test_x_vector),\n",
    "                            labels=['positive', 'negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f49a0b3-c15b-4db2-8e23-c7e0fabace46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[278,  43],\n",
       "       [ 72, 267]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(test_y, \n",
    "                            svc.predict(test_x_vector), \n",
    "                            labels=['positive', 'negative'])\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1f218-9a08-483e-97a6-144e77d049d1",
   "metadata": {},
   "source": [
    "## Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8698b-13a4-42ed-9148-98486d97b3db",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6db30ad0-2f29-42ee-aa82-416fa6b3d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=SVC(),\n",
      "             param_grid={'C': [1, 4, 8, 16, 32], 'kernel': ['linear', 'rbf']})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C': [1,4,8,16,32] ,'kernel':['linear', 'rbf']}\n",
    "svc = SVC()\n",
    "svc_grid = GridSearchCV(svc,parameters, cv=5)\n",
    "\n",
    "print(svc_grid.fit(train_x_vector, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f68a7641-aa82-45fc-9b61-c2a1762ac3c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'C': 4, 'kernel': 'rbf'}\n",
      "Score:  0.814\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros:\",svc_grid.best_params_)\n",
    "print(f\"Score: {svc_grid.best_score_: .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756912cd-234a-47df-ad6e-47ec85de363e",
   "metadata": {},
   "source": [
    "The Score we obtain is a bit lower than it was before using GridSearchCV, this could mean our current model is more honest and less prone to overfitting. The real advantage of grid search is finding hyperparameters that generalize better to new data, even if this means sacrificing a bit of apparent performance on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be50cda-4f11-4fec-9cd5-f6b559fe2b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
